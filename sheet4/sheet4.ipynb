{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILAS - Data Mining (summer 2019) - Assignment 4\n",
    "#### by Andreas Hene, Niklas Mertens, Richard Palme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sympy\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we write a function `get_repr` that returns the representative of an element `val` in the dyadic interval of level `lvl`. The representative is always chosen to be the smallest element of the dyadic array.\n",
    "$$ \\text{val} = j \\cdot 2^{h-\\text{lvl}} + \\text{rest} $$\n",
    "The representative can be computed by\n",
    "$$ j \\cdot 2^{h-\\text{lvl}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repr(val, lvl, h):\n",
    "    return math.floor(val / 2**(h-lvl)) * 2**(h-lvl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write a function `get_children` that returns the children dyadic intervals of a representative `u`. The intervals are again given by their representative. The children of `u` are `u` and\n",
    "$$ u + 2^{h-(\\text{lvl} + 1)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_children(u, lvl, h, n):\n",
    "    children = [u]\n",
    "    if lvl != h:\n",
    "        right_child = u + 2**(h - (lvl+1))\n",
    "        if right_child <= n:\n",
    "            children.append(right_child)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_p(u, p, size):\n",
    "    res = np.zeros(size, dtype=np.int16)\n",
    "    i = 0\n",
    "    while u != 0:\n",
    "        u, r = np.divmod(u, p)\n",
    "        res[i] = r\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "def _hashfunc(u, a, b, p, k):\n",
    "    return (np.dot(a, base_p(u, p, k)) + b) % p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_min_sketch(filepath, eps, delta):\n",
    "    with open(filepath) as f:\n",
    "        n = int(f.readline())\n",
    "        m = int(f.readline())\n",
    "        threshold = int(f.readline())\n",
    "    \n",
    "    d = math.ceil(math.log(1.0 / delta, 2))\n",
    "    w = math.ceil(2.0 / eps)\n",
    "    \n",
    "    # find a prime p with p >= w\n",
    "    p = w\n",
    "    while not sympy.isprime(p):\n",
    "        p += 1\n",
    "\n",
    "    # choose k such that p^k - 1 >= n\n",
    "    # i.e. k >= log(n+1, p)\n",
    "    k = math.ceil(math.log(n+1, p))\n",
    "\n",
    "    hashfuncs = []\n",
    "    for _ in range(d):\n",
    "        a = np.asarray([np.random.randint(p) for _ in range(k)])\n",
    "        b = np.random.randint(p)\n",
    "        hashfuncs.append(lambda u, a=a, b=b: _hashfunc(u, a, b, p, k))\n",
    "\n",
    "    #hashfuncs = np.zeros((d, n+1), dtype=np.int16)\n",
    "    #for i in range(d):\n",
    "    #    a = np.asarray([np.random.randint(p) for _ in range(k)])\n",
    "    #    b = np.random.randint(p)\n",
    "    #    for j in range(n+1):\n",
    "    #        hashfuncs[(i, j)] = hashfunc(j, a, b, p, k)\n",
    "\n",
    "    hashpattern = np.zeros((n+1, d, p), dtype=np.int8)\n",
    "    for u in range(n + 1):\n",
    "        for i, hashfunc in enumerate(hashfuncs):\n",
    "            hashpattern[(u, i, hashfunc(u))] = 1\n",
    "\n",
    "    h = math.ceil(math.log(n, 2))\n",
    "       \n",
    "    # note that, since w isn't necessarily a prime number,\n",
    "    # we might have to make w larger (i.e. take p instead of w)\n",
    "    C = np.zeros((h+1, d, p), dtype=np.int32)\n",
    "\n",
    "    \n",
    "    num_cores = os.cpu_count()\n",
    "    chunksize = math.ceil(m / num_cores)\n",
    "\n",
    "    chunks = pandas.read_csv(\n",
    "        filepath,\n",
    "        header=None,\n",
    "        skiprows=3,\n",
    "        squeeze=True,\n",
    "        dtype=np.int16,\n",
    "        delim_whitespace=True,\n",
    "        chunksize=chunksize\n",
    "    )\n",
    "\n",
    "    def readstream(chunk_num, chunk, h, d, p, hashpattern, return_dict):\n",
    "        # note that, since w isn't necessarily a prime number,\n",
    "        # we might have to make w larger (i.e. take p instead of w)\n",
    "        C = np.zeros((h+1, d, p), dtype=np.int32)\n",
    "        \n",
    "        for x in chunk:\n",
    "            for lvl in range(h+1):\n",
    "                u = get_repr(x, lvl, h)\n",
    "                #for i, hashfunc in enumerate(hashfuncs):\n",
    "                    #C[(lvl, i, hashfunc(u))] += 1\n",
    "                #for i in range(d):\n",
    "                #    C[(lvl, i, hashfuncs[(i, u)])] += 1\n",
    "                np.add(C[lvl], hashpattern[u], out=C[lvl])\n",
    "        return_dict[chunk_num] = C\n",
    "    \n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        job = mp.Process(target=readstream, args=(i, chunk, h, d, p, hashpattern, return_dict))\n",
    "        jobs.append(job)\n",
    "        job.start()\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "    \n",
    "    C = np.zeros((h+1, d, p), dtype=np.int32)\n",
    "    for matrix in return_dict.values():\n",
    "        np.add(C, matrix, out=C)\n",
    "    \n",
    "    # now we do BFS. the values in explore_current are\n",
    "    # the representatives of the dyadic arrays that\n",
    "    # currently get explored on this level.\n",
    "    explore_current = [0]\n",
    "    explore_next = []\n",
    "    approx_freq = np.zeros(d, dtype=np.int32)\n",
    "    for lvl in range(h + 1):\n",
    "        for u in explore_current:\n",
    "            for i, hashfunc in enumerate(hashfuncs):\n",
    "                approx_freq[i] = C[(lvl, i, hashfunc(u))]\n",
    "            #for i in range(d):\n",
    "            #    approx_freq[i] = C[(lvl, i, hashfuncs[(i, u)])]\n",
    "            if approx_freq.min() >= threshold:\n",
    "                explore_next.extend(get_children(u, lvl, h, n))\n",
    "        explore_current = explore_next\n",
    "        explore_next = []\n",
    "        \n",
    "    # prepare the output:\n",
    "    approx_frequency = []\n",
    "    for u in explore_current:\n",
    "        for i, hashfunc in enumerate(hashfuncs):\n",
    "            approx_freq[i] = C[(h, i, hashfunc(u))]\n",
    "        #for i in range(d):\n",
    "        #    approx_freq[i] = C[(h, i, hashfuncs[(i, u)])]\n",
    "        approx_frequency.append(approx_freq.min())\n",
    "        \n",
    "    return explore_current, approx_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101] [16492, 17872, 19420, 21147, 22932, 24111, 24731, 26087, 26592, 27029, 27578, 27482, 27303, 26266, 25816, 24821, 23909, 22710, 21220, 20137, 18462, 17105, 15824]\n",
      "time in seconds: 25\n"
     ]
    }
   ],
   "source": [
    "filename = [\n",
    "    'data/easy.txt',\n",
    "    'data/large_15k.txt',\n",
    "    'data/large_25k.txt',\n",
    "    'data/larger_40k.txt',\n",
    "    'data/largest_40k.txt',\n",
    "    'data/wide_1k.txt',\n",
    "]\n",
    "\n",
    "filepath = filename[1]\n",
    "#filepath = 'data/supereasy'\n",
    "    \n",
    "start = time.time()\n",
    "result, freq = count_min_sketch(filepath, eps=0.01, delta=0.01)\n",
    "end = time.time()\n",
    "elapsed_time = int(round(end - start))\n",
    "\n",
    "print(result, freq)\n",
    "print('time in seconds:', elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath = filename[0]\n",
    "#%lprun -f count_min_sketch count_min_sketch(filepath, eps=0.1, delta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brute(filepath):\n",
    "    with open(filepath) as f:\n",
    "        n = int(f.readline())\n",
    "        m = int(f.readline())\n",
    "        t = int(f.readline())\n",
    "    \n",
    "    chunks = pandas.read_csv(\n",
    "        filepath,\n",
    "        header=None,\n",
    "        skiprows=3,\n",
    "        squeeze=True,\n",
    "        dtype=np.int16,\n",
    "        delim_whitespace=True,\n",
    "        chunksize=8*10**5\n",
    "    )\n",
    "    freq = np.zeros(n+1, dtype=np.int32)\n",
    "    for chunk in chunks:\n",
    "        for x in chunk:\n",
    "            freq[x] += 1\n",
    "            \n",
    "    \n",
    "            \n",
    "    return [(i, f) for (i, f) in zip(range(n+1), list(freq)) if f >= t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1079, 16261), (1080, 17619), (1081, 19139), (1082, 20809), (1083, 22552), (1084, 23643), (1085, 24202), (1086, 25485), (1087, 25951), (1088, 26327), (1089, 26725), (1090, 26522), (1091, 26231), (1092, 25085), (1093, 24463), (1094, 23421), (1095, 22264), (1096, 20880), (1097, 19277), (1098, 17872), (1099, 16061)]\n",
      "time in seconds: 4\n"
     ]
    }
   ],
   "source": [
    "filepath = filename[1]\n",
    "    \n",
    "start = time.time()\n",
    "result = brute(filepath)\n",
    "end = time.time()\n",
    "elapsed_time = int(round(end - start))\n",
    "\n",
    "print(result)\n",
    "print('time in seconds:', elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
