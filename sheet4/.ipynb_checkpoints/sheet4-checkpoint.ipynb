{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILAS - Data Mining (summer 2019) - Assignment 4\n",
    "#### by Andreas Hene, Niklas Mertens, Richard Palme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import sympy\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we write a function `get_repr` that returns the representative of an element `val` in the dyadic interval of level `lvl`. The representative is always chosen to be the smallest element of the dyadic array.\n",
    "$$ \\text{val} = j \\cdot 2^{h-\\text{lvl}} + \\text{rest} $$\n",
    "The representative can be computed by\n",
    "$$ j \\cdot 2^{h-\\text{lvl}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repr(val, lvl, h):\n",
    "    return math.floor(val / 2**(h-lvl)) * 2**(h-lvl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write a function `get_children` that returns the children dyadic intervals of a representative `u`. The intervals are again given by their representative. The children of `u` are `u` and\n",
    "$$ u + 2^{h-(\\text{lvl} + 1)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(u, lvl, h, n):\n",
    "    children = [u]\n",
    "    if lvl != h:\n",
    "        right_child = u + 2**(h - (lvl+1))\n",
    "        if right_child <= n:\n",
    "            children.append(right_child)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_p(u, p, size):\n",
    "    res = np.zeros(size, dtype=np.int16)\n",
    "    i = 0\n",
    "    while u != 0:\n",
    "        u, r = np.divmod(u, p)\n",
    "        res[i] = r\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "def _hashfunc(u, a, b, p, k):\n",
    "    return (np.dot(a, base_p(u, p, k)) + b) % p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 0 0 1 2 2 0 1 "
     ]
    }
   ],
   "source": [
    "for u in range(9):\n",
    "    print(_hashfunc(u, [1, 2], 1, p=3, k=2), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_min_sketch(filepath, eps, delta):\n",
    "    with open(filepath) as f:\n",
    "        n = int(f.readline())\n",
    "        m = int(f.readline())         # unused\n",
    "        threshold = int(f.readline())\n",
    "    \n",
    "    d = math.ceil(math.log(1.0 / delta, 2))\n",
    "    w = math.ceil(2.0 / eps)\n",
    "    \n",
    "    # find a prime p with p >= w\n",
    "    p = w\n",
    "    while not sympy.isprime(p):\n",
    "        p += 1\n",
    "\n",
    "    # choose k such that p^k - 1 >= n\n",
    "    # i.e. k >= log(n+1, p)\n",
    "    k = math.ceil(math.log(n+1, p))\n",
    "\n",
    "    hashfuncs = []\n",
    "    for _ in range(d):\n",
    "        a = np.asarray([np.random.randint(p) for _ in range(k)])\n",
    "        b = np.random.randint(p)\n",
    "        hashfuncs.append(lambda u, a=a, b=b: _hashfunc(u, a, b, p, k))\n",
    "\n",
    "    #hashfuncs = np.zeros((d, n+1), dtype=np.int16)\n",
    "    #for i in range(d):\n",
    "    #    a = np.asarray([np.random.randint(p) for _ in range(k)])\n",
    "    #    b = np.random.randint(p)\n",
    "    #    for j in range(n+1):\n",
    "    #        hashfuncs[(i, j)] = hashfunc(j, a, b, p, k)\n",
    "\n",
    "    hashpattern = np.zeros((n+1, d, p), dtype=np.int8)\n",
    "    for u in range(n + 1):\n",
    "        for i, hashfunc in enumerate(hashfuncs):\n",
    "            hashpattern[(u, i, hashfunc(u))] = 1\n",
    "\n",
    "    h = math.ceil(math.log(n, 2))\n",
    "       \n",
    "    # note that, since w isn't necessarily a prime number,\n",
    "    # we might have to make w larger (i.e. take p instead of w)\n",
    "    C = np.zeros((h+1, d, p), dtype=np.int32)\n",
    "\n",
    "    # dtype is int16, so 2 bytes. chunksize is 10**5,\n",
    "    # so one chunk is exactly 0.2 MB and\n",
    "    # should fit into cache.\n",
    "    chunks = pandas.read_csv(\n",
    "        filepath,\n",
    "        header=None,\n",
    "        skiprows=3,\n",
    "        squeeze=True,\n",
    "        dtype=np.int16,\n",
    "        delim_whitespace=True,\n",
    "        chunksize=10**5\n",
    "    )\n",
    "\n",
    "    # process the stream. Each chunk is of type pandas.series\n",
    "    for chunk in chunks:\n",
    "        for x in chunk:\n",
    "            for lvl in range(h+1):\n",
    "                u = get_repr(x, lvl, h)\n",
    "                #for i, hashfunc in enumerate(hashfuncs):\n",
    "                    #C[(lvl, i, hashfunc(u))] += 1\n",
    "                #for i in range(d):\n",
    "                #    C[(lvl, i, hashfuncs[(i, u)])] += 1\n",
    "                np.add(C[lvl], hashpattern[u], out=C[lvl])\n",
    "    \n",
    "    # now we do BFS. the values in explore_current are\n",
    "    # the representatives of the dyadic arrays that\n",
    "    # currently get explored on this level.\n",
    "    explore_current = [0]\n",
    "    explore_next = []\n",
    "    approx_freq = np.zeros(d, dtype=np.int32)\n",
    "    for lvl in range(h + 1):\n",
    "        for u in explore_current:\n",
    "            for i, hashfunc in enumerate(hashfuncs):\n",
    "                approx_freq[i] = C[(lvl, i, hashfunc(u))]\n",
    "            #for i in range(d):\n",
    "            #    approx_freq[i] = C[(lvl, i, hashfuncs[(i, u)])]\n",
    "            if approx_freq.min() >= threshold:\n",
    "                explore_next.extend(get_children(u, lvl, h, n))\n",
    "        explore_current = explore_next\n",
    "        explore_next = []\n",
    "        \n",
    "    # prepare the output:\n",
    "    approx_frequency = []\n",
    "    for u in explore_current:\n",
    "        for i, hashfunc in enumerate(hashfuncs):\n",
    "            approx_freq[i] = C[(h, i, hashfunc(u))]\n",
    "        #for i in range(d):\n",
    "        #    approx_freq[i] = C[(h, i, hashfuncs[(i, u)])]\n",
    "        approx_frequency.append(approx_freq.min())\n",
    "        \n",
    "    return explore_current, approx_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111] [82157, 82163, 81738, 81295, 81813, 68443, 68603, 67100, 65850, 75713, 74988, 77306, 78932, 85111, 85154, 83464, 75942, 73450, 78764, 77879, 86960, 87218, 83999, 82707, 68443, 68603, 67100, 65850, 75713, 74988, 77306, 78932, 83595, 84083, 84024, 75942, 73450, 78764, 77879, 85035, 82033, 82989, 81957, 94297, 68603, 67100, 65850, 75713, 74988, 77306, 78932, 81295, 81813, 85154, 75942, 73450, 78764, 77879, 80093, 82033, 83755, 85111, 85578, 86445, 88187, 87915, 68443, 74988, 77306, 78932, 83999, 82707, 82157, 75942, 73450, 78764, 77879, 86473, 82033, 82688, 82989, 81957, 84024, 84935, 84516, 68443, 68603, 67100, 65850, 75713, 95015, 87218, 75942, 73450, 78764, 77879, 79721, 80093, 81738, 81295, 81813, 88082, 88187, 82688, 68443, 68603, 67100, 65850, 75713, 74988, 77306, 78932, 81957, 78764, 77879, 86790, 82033, 84434, 83999, 82707, 81957, 82163, 81738, 68443, 68603, 67100, 65850, 75713, 74988, 77306, 78932, 84935, 84516, 85111, 75942, 73450, 77306, 78932, 86445, 85154, 83464, 81160, 80435, 79721, 80093, 82707, 82157, 82163, 81738, 81295, 81813, 88187, 87915, 75713, 74988, 77306, 78932, 84024, 84935, 84516, 85111, 85578, 86445, 86473, 85035, 84294, 82989, 81957, 83999, 82707, 82157, 82163, 68443, 68603, 67100, 65850, 88309, 87218, 82688, 83464, 81160, 80435, 79721, 80093]\n",
      "time in seconds: 250\n"
     ]
    }
   ],
   "source": [
    "filename = [\n",
    "    'data/easy.txt',\n",
    "    'data/large_15k.txt',\n",
    "    'data/large_25k.txt',\n",
    "    'data/larger_40k.txt',\n",
    "    'data/largest_40k.txt',\n",
    "    'data/wide_1k.txt',\n",
    "]\n",
    "\n",
    "filepath = filename[1]\n",
    "#filepath = 'data/supereasy'\n",
    "    \n",
    "start = time.time()\n",
    "result, freq = count_min_sketch(filepath, eps=0.1, delta=0.1)\n",
    "end = time.time()\n",
    "elapsed_time = int(round(end - start))\n",
    "\n",
    "print(result, freq)\n",
    "print('time in seconds:', elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = filename[0]\n",
    "#%lprun -f count_min_sketch count_min_sketch(filepath, eps=0.1, delta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute(filepath):\n",
    "    with open(filepath) as f:\n",
    "        n = int(f.readline())\n",
    "        m = int(f.readline())\n",
    "        t = int(f.readline())\n",
    "    \n",
    "    chunks = pandas.read_csv(\n",
    "        filepath,\n",
    "        header=None,\n",
    "        skiprows=3,\n",
    "        squeeze=True,\n",
    "        dtype=np.int16,\n",
    "        delim_whitespace=True,\n",
    "        chunksize=8*10**5\n",
    "    )\n",
    "    freq = np.zeros(n+1, dtype=np.int32)\n",
    "    for chunk in chunks:\n",
    "        for x in chunk:\n",
    "            freq[x] += 1         \n",
    "    return [(i, f) for (i, f) in zip(range(n+1), list(freq)) if f >= t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 4)]\n",
      "time in seconds: 0\n"
     ]
    }
   ],
   "source": [
    "#filepath = filename[0]\n",
    "    \n",
    "start = time.time()\n",
    "result = brute(filepath)\n",
    "end = time.time()\n",
    "elapsed_time = int(round(end - start))\n",
    "\n",
    "print(result)\n",
    "print('time in seconds:', elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
